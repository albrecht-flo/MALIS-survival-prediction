{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3e0ae1d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'null' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3256\\1199844415.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmutil\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\MALIS-Project\\MALIS-survival-prediction-main\\data\\utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m   {\n\u001b[0;32m      4\u001b[0m    \u001b[1;34m\"cell_type\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"code\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m    \u001b[1;34m\"execution_count\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnull\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m    \u001b[1;34m\"id\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"4f6fc23b\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m    \u001b[1;34m\"metadata\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'null' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import utils as mutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eb5fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train = pd.read_csv(\"titanic/train.csv\")\n",
    "titanic_test = pd.read_csv(\"titanic/test.csv\")\n",
    "titanic_submission_ex = pd.read_csv(\"titanic/gender_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395ca7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53189ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf536f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're defining a function missing data to check if the values missing in the differents data_set and then \n",
    "#to decide how to handle missing values\n",
    "\n",
    "def missingdata(data):\n",
    "    total = data.isnull().sum().sort_values(ascending = False)\n",
    "    percent = (data.isnull().sum()/data.isnull().count()*100).sort_values(ascending = False)\n",
    "    ms=pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    ms= ms[ms[\"Percent\"] > 0]\n",
    "    f,ax =plt.subplots(figsize=(8,6))\n",
    "    plt.xticks(rotation='90')\n",
    "    fig=sns.barplot(ms.index, ms[\"Percent\"],color=\"green\",alpha=0.8)\n",
    "    plt.xlabel('Features', fontsize=15)\n",
    "    plt.ylabel('Percent of missing values', fontsize=15)\n",
    "    plt.title('Percent missing data by feature', fontsize=15)\n",
    "    return ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c4864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "missingdata(titanic_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f808e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "missingdata(titanic_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d5537a",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train['Embarked'].fillna(titanic_train['Embarked'].mode()[0], inplace = True) # We remark that there were values for\n",
    "#the Embarked futures in our titanic_test missing in the titanic_train. So we decide to fill the titanic_train as many values\n",
    "#were missed.\n",
    "titanic_test['Fare'].fillna(titanic_test['Fare'].median(), inplace = True)\n",
    "\n",
    "\n",
    "#Cabin Featueres has more than 75% of missing data in both Test and train data so we are remove the Cabin\n",
    "drop_column = ['Cabin']\n",
    "titanic_train.drop(drop_column, axis=1, inplace = True)\n",
    "titanic_test.drop(drop_column,axis=1,inplace=True) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7876040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Both the test and train Age features contains more the 15% of missing Data so we are fill with the median¶\n",
    "titanic_train['Age'].fillna(titanic_train['Age'].mean(), inplace = True)\n",
    "titanic_test['Age'].fillna(titanic_test['Age'].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d0427a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are now checking if all null/nan values are well replaced.\n",
    "print('check the nan value in train data')\n",
    "print(titanic_train.isnull().sum())\n",
    "print('___'*30)\n",
    "print('check the nan value in test data')\n",
    "print(titanic_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552dc744",
   "metadata": {},
   "outputs": [],
   "source": [
    "## combine test and train as single to apply some function\n",
    "all_data=[titanic_train,titanic_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598cc68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new feature FamilySize as a combination of SibSp and Parch\n",
    "for dataset in all_data:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec109231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Define function to extract titles from passenger names\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "# Create a new feature Title, containing the titles of passenger names\n",
    "for dataset in all_data:\n",
    "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "# Group all non-common titles into one single grouping \"Rare\"\n",
    "for dataset in all_data:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', \n",
    "                                                 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36405e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c8fcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a binary for age features\n",
    "for dataset in all_data:\n",
    "    dataset['Age_bin'] = pd.cut(dataset['Age'], bins=[0,12,20,50,95,], labels=['Children','Teenage','Adult','Elder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61eb90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a binary for fare features\n",
    "for dataset in all_data:\n",
    "    dataset['Fare_bin'] = pd.cut(dataset['Fare'], bins=[0,7.91,14.45,31,120], labels=['Low_fare','Median_fare','Average_fare','High_fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b31498",
   "metadata": {},
   "outputs": [],
   "source": [
    "### for keeping a reference of our numerical analysis, we save a copy of the data\n",
    "trainset=titanic_train\n",
    "testset=titanic_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddfcb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dat=[trainset,testset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c4375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.columns\n",
    "testset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cca6dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in all_dat:\n",
    "    drop_column = ['Age','Fare','Name','Ticket']\n",
    "    dataset.drop(drop_column, axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218983dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are dropping PassengerId column because is just a coutner id\n",
    "drop_column = ['PassengerId']\n",
    "trainset.drop(drop_column, axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "51356884",
   "metadata": {},
   "outputs": [],
   "source": [
    " #now every thing almost ready only one step we converted the catergical features in numerical by using dummy variable¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3b41680d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Sex', 'Title', 'Age_bin', 'Embarked', 'Fare_bin'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3256\\2659703231.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m trainset = pd.get_dummies(trainset, columns = [\"Sex\",\"Title\",\"Age_bin\",\"Embarked\",\"Fare_bin\"],\n\u001b[0m\u001b[0;32m      2\u001b[0m                              prefix=[\"Sex\",\"Title\",\"Age_type\",\"Em_type\",\"Fare_type\"])\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input must be a list-like for parameter `columns`\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m             \u001b[0mdata_to_encode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m         \u001b[1;31m# validate prefixes and separator to avoid silently dropping cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3509\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3510\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3511\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3513\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5794\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5796\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5797\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5798\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5854\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5855\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5856\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5858\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['Sex', 'Title', 'Age_bin', 'Embarked', 'Fare_bin'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "trainset = pd.get_dummies(trainset, columns = [\"Sex\",\"Title\",\"Age_bin\",\"Embarked\",\"Fare_bin\"],\n",
    "                             prefix=[\"Sex\",\"Title\",\"Age_type\",\"Em_type\",\"Fare_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e92dc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = pd.get_dummies(testset, columns = [\"Sex\",\"Title\",\"Age_bin\",\"Embarked\",\"Fare_bin\"],\n",
    "                             prefix=[\"Sex\",\"Title\",\"Age_type\",\"Em_type\",\"Fare_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb34fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(trainset.corr(),annot=True,cmap='RdYlGn',linewidths=0.2) #data.corr()-->correlation matrix\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(20,12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff93370c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split #for split the data\n",
    "from sklearn.metrics import accuracy_score  #for accuracy_score\n",
    "from sklearn.model_selection import KFold #for K-fold cross validation\n",
    "from sklearn.model_selection import cross_val_score #score evaluation\n",
    "from sklearn.model_selection import cross_val_predict #prediction\n",
    "from sklearn.metrics import confusion_matrix #for confusion matrix\n",
    "all_features = trainset.drop(\"Survived\",axis=1)\n",
    "Targeted_feature = trainset[\"Survived\"]\n",
    "X_train,X_test,y_train,y_test = train_test_split(all_features,Targeted_feature,test_size=0.3,random_state=42)\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc110fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "model.fit(X_train,y_train)\n",
    "prediction_knn_train=model.predict(X_train)\n",
    "prediction_knn_test=model.predict(X_test)\n",
    "print('--------------The Accuracy of the model----------------------------')\n",
    "print('The accuracy of the K Nearst Neighbors Classifier on trainset is',round(accuracy_score(prediction_knn_train,y_train)*100,2))\n",
    "print('The accuracy of the K Nearst Neighbors Classifier on testset is',round(accuracy_score(prediction_knn_test,y_test)*100,2))\n",
    "kfold = KFold(n_splits=10, random_state=22, shuffle=True) # k=10, split the data into 10 equal parts\n",
    "result_knn=cross_val_score(model,all_features,Targeted_feature,cv=10,scoring='accuracy')\n",
    "print('The cross validated score for K Nearest Neighbors Classifier is:',round(result_knn.mean()*100,2))\n",
    "y_pred = cross_val_predict(model,all_features,Targeted_feature,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516e8fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutil.plot_roc(model, X_test, y_test title=\"ROC curve for best fit model without feature engineering (KNN, Titanic)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c4ed2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = mutil.calc_f1(model, X_test, y_test)\n",
    "print(f\"Weighted F1-score = {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
